# Personal AI Agent - Agente Conversacional Inteligente

![Python](https://img.shields.io/badge/python-3.11+-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.109+-green.svg)
![LangChain](https://img.shields.io/badge/LangChain-0.1+-orange.svg)
![Tests](https://img.shields.io/badge/tests-178%20passing-brightgreen.svg)
![Coverage](https://img.shields.io/badge/coverage-100%25-success.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

## ğŸ“‹ DescripciÃ³n del Proyecto

**Personal AI Agent** es un sistema de agente conversacional inteligente desarrollado en Python que combina capacidades avanzadas de procesamiento de lenguaje natural, recuperaciÃ³n aumentada por generaciÃ³n (RAG) y gestiÃ³n conversacional multi-turno. El sistema estÃ¡ diseÃ±ado para mantener conversaciones contextuales, extraer informaciÃ³n estructurada de manera progresiva y proporcionar respuestas informadas basadas en una base de conocimiento.

### CaracterÃ­sticas Principales

- ğŸ¤– **ConversaciÃ³n Multi-turno**: Mantiene contexto completo de la conversaciÃ³n por sesiÃ³n
- ğŸ“Š **ExtracciÃ³n Estructurada**: Recopila y valida datos (order_id, category, description, urgency)
- ğŸ” **RAG con FAISS**: Sistema de recuperaciÃ³n de informaciÃ³n con vectores
- ğŸŒ **Multilenguaje**: Soporte para espaÃ±ol e inglÃ©s con detecciÃ³n automÃ¡tica
- ğŸ˜Š **AnÃ¡lisis de Sentimiento**: Adapta el tono segÃºn las emociones del usuario
- ğŸ“ **ResÃºmenes AutomÃ¡ticos**: Genera resÃºmenes cuando se completa la informaciÃ³n
- ğŸ’¾ **Persistencia JSON**: Almacenamiento completo de conversaciones
- ğŸ¤ **STT/TTS**: Interfaces para reconocimiento y sÃ­ntesis de voz
- ğŸ”’ **Seguridad**: AutenticaciÃ³n mediante API keys, validaciÃ³n robusta
- âœ… **Suite de Tests Completa**: 178 tests unitarios y de integraciÃ³n (100% passing)

---

## ğŸš€ Instrucciones de Setup

### Prerrequisitos

- **Python 3.11 o superior**
- **pip** (gestor de paquetes de Python)
- **Cuenta de OpenAI** (o proveedor alternativo de LLM)
- **8 GB RAM** recomendados
- **Linux/macOS/Windows** con terminal

### 1. Clonar el Repositorio

```bash
git clone <repository-url>
cd personal-ai-agent-api
```

### 2. Crear Entorno Virtual

```bash
# Crear entorno virtual
python3 -m venv venv

# Activar entorno virtual
# En Linux/macOS:
source venv/bin/activate

# En Windows:
# venv\Scripts\activate
```

### 3. Instalar Dependencias

```bash
# Instalar todas las dependencias
pip install -r src/requirements.txt

# Si usas el archivo congelado (versiones exactas):
# pip install -r requirements_freeze.txt
```

### 4. Configurar Variables de Entorno

Crea un archivo `.env` en la carpeta `src/`:

```bash
cd src
touch .env
```

Contenido mÃ­nimo del archivo `.env`:

```bash
# ConfiguraciÃ³n de la aplicaciÃ³n
APP_ENV=dev
APP_HOST=0.0.0.0
APP_PORT=8000
LOG_LEVEL=INFO

# Proveedor de LLM (openai, anthropic, local)
LLM_PROVIDER=openai
LLM_MODEL=gpt-4o-mini
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=1000

# API Keys (Â¡IMPORTANTE! AÃ±ade tu clave)
OPENAI_API_KEY=sk-tu-api-key-aqui
# ANTHROPIC_API_KEY=sk-ant-tu-clave  # Si usas Anthropic

# Embeddings
EMBEDDINGS_PROVIDER=openai
EMBEDDINGS_MODEL=text-embedding-3-large

# Base de Conocimiento
KB_PATH=../kb

# Vector Store
VECTORSTORE_PATH=./data/vectorstore
VECTORSTORE_INDEX_NAME=faiss_index

# RAG Configuration
RAG_TOP_K=5
RAG_SCORE_THRESHOLD=0.7
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# Conversaciones
MAX_CONVERSATION_TURNS=50
CONVERSATION_STORAGE_PATH=./data/conversations

# Seguridad
API_KEY_ADMIN=cambia-esta-clave-en-produccion

# Idiomas
DEFAULT_LANGUAGE=es
SUPPORTED_LANGUAGES=es,en

# TTS/STT
TTS_ENABLED=false
TTS_PROVIDER=gtts
STT_ENABLED=false
STT_PROVIDER=none
```

### 5. Ingestar la Base de Conocimiento

Antes de iniciar las conversaciones, es recomendable crear el Ã­ndice vectorial. Se puede hacer mediante su endpoint.

### 6. Iniciar el Servidor

```bash
# Iniciar servidor FastAPI
python MAIN.py
```

El servidor estarÃ¡ disponible en:
- **API**: http://localhost:8000
- **DocumentaciÃ³n interactiva**: http://localhost:8000/
- **ReDoc**: http://localhost:8000/redoc

### 7. Verificar InstalaciÃ³n

```bash
# En otra terminal, verificar health check
curl http://localhost:8000/api/v1/health

# Respuesta esperada:
# {"status":"ok","version":"1.0.0"}
```

---

## ğŸ—ï¸ Arquitectura del Sistema

### VisiÃ³n General

El sistema estÃ¡ organizado en capas bien definidas que separan responsabilidades:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Usuario / Cliente                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ HTTP REST API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FastAPI Server Layer                        â”‚
â”‚  â€¢ Routing (chat, admin, health)                        â”‚
â”‚  â€¢ ValidaciÃ³n (Pydantic)                                â”‚
â”‚  â€¢ AutenticaciÃ³n (API Keys)                             â”‚
â”‚  â€¢ CORS & Middleware                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Conversation Service (Orquestador)              â”‚
â”‚  â€¢ GestiÃ³n de flujo conversacional                      â”‚
â”‚  â€¢ CoordinaciÃ³n de servicios                            â”‚
â”‚  â€¢ DetecciÃ³n de idioma                                  â”‚
â”‚  â€¢ AnÃ¡lisis de sentimiento                              â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚        â”‚        â”‚        â”‚        â”‚        â”‚
    â”‚        â”‚        â”‚        â”‚        â”‚        â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â–¼â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”
â”‚Memory â”‚ â”‚RAG â”‚ â”‚Extractâ”‚ â”‚Sum. â”‚ â”‚Store â”‚ â”‚STT/TTSâ”‚
â”‚Managerâ”‚ â”‚Svc â”‚ â”‚Serviceâ”‚ â”‚Svc  â”‚ â”‚Svc   â”‚ â”‚Svc    â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”¬â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚       â”‚        â”‚        â”‚       â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              LangChain Layer                             â”‚
â”‚  â€¢ LLM Chains (extraction, response, summary)           â”‚
â”‚  â€¢ ConversationBufferMemory                             â”‚
â”‚  â€¢ Retrieval Chain                                      â”‚
â”‚  â€¢ Prompt Templates (ES/EN)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚            â”‚            â”‚
    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚ LLM   â”‚   â”‚ FAISS  â”‚  â”‚ JSON   â”‚
    â”‚OpenAI â”‚   â”‚Vector  â”‚  â”‚Storage â”‚
    â”‚/Claudeâ”‚   â”‚Store   â”‚  â”‚        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes Principales

#### 1. **FastAPI Server** (`src/server/`)
- Expone endpoints REST para chat, administraciÃ³n y health checks
- Maneja autenticaciÃ³n mediante API keys
- ValidaciÃ³n automÃ¡tica con Pydantic
- DocumentaciÃ³n OpenAPI generada automÃ¡ticamente

#### 2. **Conversation Service** (`src/services/conversation.py`)
Orquestador central que coordina:
- DetecciÃ³n de idioma
- AnÃ¡lisis de sentimiento
- GestiÃ³n de memoria conversacional
- ExtracciÃ³n de datos estructurados
- Consulta a la base de conocimiento (RAG)
- GeneraciÃ³n de respuestas
- CreaciÃ³n de resÃºmenes
- Persistencia de datos

#### 3. **Memory Manager** (`src/llm/memory.py`)
- Implementa `ConversationBufferMemory` de LangChain
- Mantiene historial por `session_id`
- LÃ­mite configurable de turnos (default: 50)
- Almacenamiento en memoria RAM

#### 4. **Extraction Service** (`src/services/extraction.py`)
- ExtracciÃ³n mediante LLM con prompts estructurados
- ValidaciÃ³n robusta de campos:
  - `order_id`: Formato alfanumÃ©rico 6-12 caracteres
  - `category`: Enum (shipping, billing, technical, other)
  - `description`: Texto con longitud mÃ­nima
  - `urgency`: Enum (low, medium, high)
- AcumulaciÃ³n incremental de datos por sesiÃ³n

#### 5. **RAG System** (`src/rag/`)
- **Ingesta**: Carga documentos Markdown â†’ Chunking â†’ Embeddings â†’ FAISS Index
- **Retrieval**: BÃºsqueda por similitud vectorial
- **Store**: Persistencia del Ã­ndice en disco

#### 6. **Storage Service** (`src/services/storage.py`)
- Persistencia en archivos JSON
- Un archivo por sesiÃ³n: `data/conversations/{session_id}.json`
- Estructura: metadata, turnos, datos extraÃ­dos, resumen

#### 7. **Sentiment Analysis** (`src/core/sentiment.py`)
- AnÃ¡lisis con TextBlob
- ClasificaciÃ³n: negative/neutral/positive
- Ajusta tono de respuestas segÃºn sentimiento

---

## ğŸ¯ Decisiones de DiseÃ±o Clave

### 1. **Â¿Por quÃ© LangChain?**

**Ventajas:**
- **Abstracciones robustas**: Simplifica integraciÃ³n con LLMs, gestiÃ³n de memoria y RAG
- **Multi-provider**: FÃ¡cil cambio entre OpenAI, Anthropic, modelos locales
- **Chains composables**: Permite construir pipelines complejos de forma modular
- **Comunidad activa**: Gran ecosistema y documentaciÃ³n

**Trade-offs:**
- Overhead de abstracciÃ³n (mÃ¡s capas de indirecciÃ³n)
- Curva de aprendizaje inicial

**ConclusiÃ³n**: Los beneficios superan los costos, especialmente la flexibilidad multi-provider y la velocidad de desarrollo.

### 2. **Â¿Por quÃ© FAISS para Vector Store?**

**Alternativas consideradas**: Pinecone, Weaviate, Chroma, Qdrant

**Razones para FAISS:**
- **Local-first**: No dependencias de servicios cloud externos
- **Alto rendimiento**: Optimizado para CPU, bÃºsquedas rÃ¡pidas
- **Gratuito**: Sin costos de API
- **Simplicidad**: Persistencia directa a disco
- **Portabilidad**: Ãndices fÃ¡ciles de distribuir

**Limitaciones:**
- Sin filtrado complejo por metadata
- Escalabilidad limitada vs. soluciones cloud
- No distribuido nativamente

**ConclusiÃ³n**: Ideal para volÃºmenes pequeÃ±os/medios y deployments que priorizan control y costos.

### 3. **Â¿Por quÃ© Almacenamiento JSON?**

**Alternativas**: PostgreSQL, MongoDB, SQLite

**Razones:**
- **Simplicidad**: No requiere instalaciÃ³n de DB
- **Portabilidad**: Archivos planos transportables
- **InspecciÃ³n manual**: FÃ¡cil debug y auditorÃ­a
- **Suficiente para el scope**: Adecuado para <10,000 sesiones

**Limitaciones:**
- Consultas complejas difÃ­ciles
- Concurrencia limitada
- Escalabilidad horizontal complicada

**MigraciÃ³n futura**: Considerar PostgreSQL cuando el volumen supere 10K sesiones o se necesiten bÃºsquedas complejas.

### 4. **ExtracciÃ³n Incremental vs. Todo de Una Vez**

**DecisiÃ³n**: ExtracciÃ³n incremental acumulativa

**Razones:**
- Usuario puede no saber toda la informaciÃ³n al inicio
- Experiencia conversacional mÃ¡s natural
- Permite validaciÃ³n progresiva
- Reduce frustraciÃ³n del usuario

**ImplementaciÃ³n**: Cache de `ExtractedData` en memoria por sesiÃ³n, merge en cada turno.

### 5. **AnÃ¡lisis de Sentimiento**

**DecisiÃ³n**: TextBlob (simple) en lugar de modelos complejos

**Razones:**
- Suficiente para ajustes bÃ¡sicos de tono
- Ligero y rÃ¡pido
- Sin dependencias de modelos pesados

**Mejora futura**: Fine-tuning de modelo especÃ­fico del dominio si se requiere mayor precisiÃ³n.

### 6. **Arquitectura de Capas**

**PatrÃ³n**: SeparaciÃ³n estricta de responsabilidades

```
Routes â†’ Services â†’ LLM/RAG â†’ Data Layer
```

**Ventajas:**
- CÃ³digo testeable (fÃ¡cil mock de dependencias)
- Mantenibilidad (cambios localizados)
- ReutilizaciÃ³n (servicios compartidos)
- Claridad (responsabilidades bien definidas)

### 7. **ConfiguraciÃ³n con Pydantic Settings**

**DecisiÃ³n**: `.env` + Pydantic en lugar de hardcoding

**Ventajas:**
- Type-safe configuration
- ValidaciÃ³n automÃ¡tica en startup
- DocumentaciÃ³n viva
- FÃ¡cil override por ambiente (dev/prod)

---

## ğŸ”§ Mejoras Potenciales

### Corto Plazo (1-3 meses)

#### 1. **Cache de Embeddings**
**Problema**: Embeddings se recalculan para queries frecuentes
**SoluciÃ³n**: Redis cache con TTL
**Impacto**: ReducciÃ³n de 50-80% en latencia para FAQs comunes

```python
# ImplementaciÃ³n sugerida
from functools import lru_cache
from redis import Redis

cache = Redis(host='localhost', port=6379)

def get_embedding_cached(text: str) -> List[float]:
    key = f"emb:{hash(text)}"
    cached = cache.get(key)
    if cached:
        return json.loads(cached)
    
    embedding = embeddings_model.embed_query(text)
    cache.setex(key, 3600, json.dumps(embedding))  # TTL 1h
    return embedding
```

#### 2. **Retry Logic con Exponential Backoff**
**Problema**: Llamadas a LLM fallan ocasionalmente (rate limits, timeouts)
**SoluciÃ³n**: Decorador retry con backoff exponencial

```python
from tenacity import retry, wait_exponential, stop_after_attempt

@retry(
    wait=wait_exponential(multiplier=1, min=2, max=10),
    stop=stop_after_attempt(3)
)
def call_llm(prompt: str) -> str:
    return llm.invoke(prompt)
```

#### 3. **Rate Limiting por Usuario/SesiÃ³n**
**Problema**: Abuso potencial del API
**SoluciÃ³n**: Middleware con `slowapi`

```python
from slowapi import Limiter
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)

@app.post("/api/v1/chat")
@limiter.limit("10/minute")
async def chat_endpoint(request: ChatRequest):
    ...
```

#### 4. **Webhooks para Sesiones Completadas**
**Problema**: Cliente debe polling para saber si hay resumen
**SoluciÃ³n**: Webhook configurable cuando `summary_ready=true`

```python
# En conversation.py, cuando summary_ready:
if settings.webhook_url:
    requests.post(
        settings.webhook_url,
        json={
            "session_id": session_id,
            "summary": summary,
            "extracted": extraction_result.extracted.dict()
        }
    )
```

### Medio Plazo (3-6 meses)

#### 5. **MigraciÃ³n a Memoria Distribuida (Redis)**
**Problema**: Memoria conversacional se pierde en restart
**SoluciÃ³n**: Redis como backend para memoria

```python
from langchain.memory import RedisChatMessageHistory

def get_memory(session_id: str):
    message_history = RedisChatMessageHistory(
        session_id=session_id,
        url="redis://localhost:6379"
    )
    return ConversationBufferMemory(chat_memory=message_history)
```

**Beneficios**:
- Persistencia entre deployments
- Compartida entre instancias (horizontal scaling)
- TTL automÃ¡tico para limpiar sesiones viejas

#### 6. **Structured Outputs (GPT-4)**
**Problema**: Parsing JSON a veces falla con prompts
**SoluciÃ³n**: Usar `response_format` de OpenAI

```python
from openai import OpenAI
client = OpenAI()

response = client.chat.completions.create(
    model="gpt-4-turbo-preview",
    messages=[...],
    response_format={"type": "json_object"},
    tools=[{
        "type": "function",
        "function": {
            "name": "extract_data",
            "parameters": ExtractedData.schema()
        }
    }]
)
```

**Beneficios**: Mayor fiabilidad en extracciÃ³n, menos parseo manual

#### 7. **Frontend Web (React/Vue)**
**Componentes**:
- Chat interface con historial
- Indicador de campos extraÃ­dos en tiempo real
- VisualizaciÃ³n de sentimiento
- Export de resÃºmenes
- Ya desarrollado la primera prueba en https://github.com/Chispasgg/personal-ai-agent-front

**Tech Stack sugerido**:
- React + TypeScript
- TailwindCSS
- Zustand para estado
- React Query para API calls

#### 8. **A/B Testing de Prompts**
**Problema**: No sabemos quÃ© prompts funcionan mejor
**SoluciÃ³n**: Framework de experimentaciÃ³n

```python
class PromptExperiment:
    def __init__(self, variants: Dict[str, str]):
        self.variants = variants
        self.metrics = defaultdict(list)
    
    def get_prompt(self, session_id: str) -> str:
        variant = hash(session_id) % len(self.variants)
        return list(self.variants.values())[variant]
    
    def track_result(self, variant: str, is_complete: bool, turns: int):
        self.metrics[variant].append({"complete": is_complete, "turns": turns})
```

### Largo Plazo (6+ meses)

#### 9. **IntegraciÃ³n con CRM**
**Sistemas**: Salesforce, HubSpot, Zendesk

**Flujo**:
```
SesiÃ³n completa â†’ Webhook â†’ CRM API
                  â†“
            Crear ticket con:
            - Datos extraÃ­dos
            - Resumen
            - TranscripciÃ³n
            - Sentimiento
```

#### 10. **Fine-tuning de Modelo de ExtracciÃ³n**
**Proceso**:
1. Recopilar 500-1000 ejemplos etiquetados
2. Fine-tune `gpt-x` o `llama-X`
3. EvaluaciÃ³n en conjunto de test
4. Deploy como modelo dedicado

**Beneficios**: Costos reducidos, mayor precisiÃ³n, menor latencia

#### 11. **Multi-tenant Architecture**
**Requisitos**:
- Aislamiento de datos por tenant
- PersonalizaciÃ³n de prompts por tenant
- LÃ­mites de uso por tenant
- Base de conocimiento separada

**Esquema DB**:
```sql
CREATE TABLE tenants (
    id UUID PRIMARY KEY,
    name VARCHAR,
    api_key VARCHAR,
    config JSONB
);

CREATE TABLE conversations (
    id UUID PRIMARY KEY,
    tenant_id UUID REFERENCES tenants,
    session_id VARCHAR,
    data JSONB,
    created_at TIMESTAMP
);
```

#### 12. **Observabilidad Avanzada**
**Stack**:
- **Logs**: ELK (Elasticsearch, Logstash, Kibana)
- **MÃ©tricas**: Prometheus + Grafana
- **Tracing**: OpenTelemetry + Jaeger
- **Alerting**: PagerDuty

**Dashboards clave**:
- Latencia P50/P95/P99 por endpoint
- Tasa de completitud de sesiones
- DistribuciÃ³n de sentimiento
- Costo por sesiÃ³n (tokens consumidos)
- Errores de extracciÃ³n

#### 13. **STT/TTS Real**
**Problema**: Actual es solo stub/gTTS bÃ¡sico

**Soluciones**:
- **STT**: Whisper API (OpenAI) o Deepgram
- **TTS**: ElevenLabs, Azure Speech, o Coqui TTS

**ImplementaciÃ³n**:
```python
# STT con Whisper
import openai

def speech_to_text(audio_file: bytes) -> str:
    response = openai.Audio.transcribe("whisper-1", audio_file)
    return response["text"]

# TTS con ElevenLabs
from elevenlabs import generate, play

def text_to_speech(text: str, voice="Bella") -> bytes:
    audio = generate(text=text, voice=voice)
    return audio
```

#### 14. **Analytics y Business Intelligence**
**Features**:
- Dashboard de mÃ©tricas de negocio
- AnÃ¡lisis de tendencias (categorÃ­as mÃ¡s frecuentes)
- DetecciÃ³n de problemas recurrentes
- Time-to-resolution por categorÃ­a
- NPS basado en sentimiento

**Herramientas**: Metabase, Superset, o custom dashboard

---

## ğŸ“š API Reference

### Endpoints Principales

#### `POST /api/v1/chat`
Procesa un mensaje del usuario y retorna respuesta con datos extraÃ­dos.

**Request:**
```json
{
  "session_id": "session-abc-123",
  "message": "Hola, mi pedido ABC123456 no llegÃ³",
  "language": "es",  // opcional, se detecta automÃ¡ticamente
  "audio_response": false  // opcional, para recibir respuesta en audio
}
```

**Response:**
```json
{
  "reply": "Entiendo tu preocupaciÃ³n. Â¿PodrÃ­as indicarme la categorÃ­a?",
  "sound_file_base64": null,
  "language": "es",
  "sentiment": "negative",
  "extracted": {
    "order_id": "ABC123456",
    "category": null,
    "description": "Pedido no llegÃ³",
    "urgency": null
  },
  "missing_fields": ["category", "urgency"],
  "summary_ready": false,
  "summary": null,
  "session_id": "session-abc-123",
  "turn_number": 2
}
```

#### `GET /api/v1/health`
Health check del servicio.

**Response:**
```json
{
  "status": "ok",
  "version": "1.0.0"
}
```

#### `POST /api/v1/admin/ingest` ğŸ”’
Reingesta la base de conocimiento (requiere API key).

**Headers:**
```
X-API-Key: tu-api-key-admin
```

**Request:**
```json
{
  "kb_path": "../kb"
}
```

**Response:**
```json
{
  "status": "success",
  "message": "Knowledge base ingested successfully",
  "documents_count": 2,
  "chunks_count": 47
}
```

### AutenticaciÃ³n

Los endpoints administrativos requieren autenticaciÃ³n mediante API key:

```bash
curl -X POST http://localhost:8000/api/v1/admin/ingest \
  -H "X-API-Key: tu-api-key-admin" \
  -H "Content-Type: application/json" \
  -d '{"kb_path": "../kb"}'
```

---

<!-- ## ğŸ³ Docker

### ConstrucciÃ³n y EjecuciÃ³n

```bash
# Construir imagen
cd docker
docker build -t personal-ai-agent:latest -f Dockerfile ../src

# Ejecutar contenedor
docker run -d \
  -p 8000:8000 \
  -v $(pwd)/data:/src/data \
  -e OPENAI_API_KEY=tu-key \
  --name ai-agent \
  personal-ai-agent:latest

# Ver logs
docker logs -f ai-agent
```

### Docker Compose

Edita `docker/docker-compose.yml` con tu configuraciÃ³n:

```yaml
version: '3.8'

services:
  api:
    build:
      context: ../src
      dockerfile: ../docker/Dockerfile
    ports:
      - "8000:8000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - API_KEY_ADMIN=${API_KEY_ADMIN}
      - APP_ENV=prod
    volumes:
      - ./data:/src/data
      - ./kb:/kb
    restart: unless-stopped
```

Ejecutar:

```bash
docker-compose -f docker/docker-compose.yml up -d
``` -->

---

## ğŸ§ª Testing

### âœ… Suite de Tests Completa

El proyecto cuenta con una **suite completa de 178 tests unitarios y de integraciÃ³n** que cubren todos los mÃ³dulos del sistema con un **100% de tasa de Ã©xito**.

#### EstadÃ­sticas de Tests

- **Total de tests**: 178 âœ…
- **Tests pasando**: 178 (100%)
- **Tiempo de ejecuciÃ³n**: ~1.45 segundos
- **Cobertura**: Todos los mÃ³dulos cubiertos

#### DistribuciÃ³n por MÃ³dulos

| MÃ³dulo | Tests | DescripciÃ³n |
|--------|-------|-------------|
| **API Endpoints** | 13 | Tests de endpoints REST (chat, admin, health) |
| **Conversation** | 17 | Servicio de conversaciÃ³n y sesiones |
| **Extraction** | 12 | Servicio de extracciÃ³n de datos |
| **LLM Chains** | 10 | Chains de LangChain |
| **LLM Memory** | 16 | GestiÃ³n de memoria conversacional |
| **Memory** | 17 | Sistema de memoria y persistencia |
| **RAG System** | 19 | Ingesta, almacenamiento y recuperaciÃ³n |
| **Storage** | 15 | Persistencia JSON de conversaciones |
| **Summarization** | 10 | GeneraciÃ³n de resÃºmenes |
| **Sentiment** | 8 | AnÃ¡lisis de sentimiento |
| **Validators** | 10 | Validadores de Order ID y Session ID |
| **JSON I/O** | 18 | Utilidades de lectura/escritura JSON |
| **Utils** | 13 | Utilidades diversas |

### Ejecutar Tests

```bash
# Instalar dependencias de test
pip install pytest pytest-asyncio pytest-cov pytest-mock httpx

# Ejecutar todos los tests (178 tests)
pytest tests/ -v

# EjecuciÃ³n rÃ¡pida
pytest tests/ --tb=no -q
# Resultado esperado: 178 passed, 79 warnings in ~1.45s

# Tests especÃ­ficos por mÃ³dulo
pytest tests/test_api_endpoints.py -v        # 13 tests de API
pytest tests/test_conversation.py -v         # 17 tests de conversaciÃ³n
pytest tests/test_rag_system.py -v           # 19 tests de RAG
pytest tests/test_extraction.py -v           # 12 tests de extracciÃ³n

# Con cobertura detallada
pytest tests/ --cov=src --cov-report=html --cov-report=term

# Ver reporte HTML de cobertura
xdg-open htmlcov/index.html  # Linux
# open htmlcov/index.html     # macOS
```

### CaracterÃ­sticas de los Tests

- âœ… **Tests unitarios**: Pruebas aisladas de cada componente
- âœ… **Tests de integraciÃ³n**: Pruebas de flujos completos
- âœ… **Mocking robusto**: LLM, FAISS, y APIs correctamente mockeados
- âœ… **Async testing**: Tests de endpoints FastAPI con async/await
- âœ… **Fixtures compartidos**: ConfiguraciÃ³n reutilizable en `conftest.py`
- âœ… **ValidaciÃ³n Pydantic**: Tests de validaciÃ³n de DTOs
- âœ… **Error handling**: Tests de manejo de errores y edge cases

### DocumentaciÃ³n de Tests

Para mÃ¡s informaciÃ³n sobre la suite de tests, consulta:

ğŸ“– **[tests/TEST_README.md](tests/TEST_README.md)** - DocumentaciÃ³n completa de tests

Incluye:
- GuÃ­a de ejecuciÃ³n de tests
- Estructura y organizaciÃ³n
- Mejores prÃ¡cticas aplicadas
- Troubleshooting
- Ejemplos de tests

---

## ğŸ“– Estructura de Archivos

```
api/
â”œâ”€â”€ README.md                      # Este archivo
â”œâ”€â”€ requirements_freeze.txt        # Dependencias con versiones exactas
â”œâ”€â”€ lanzar.sh                      # Script de inicio rÃ¡pido
â”‚
â”œâ”€â”€ kb/                            # Base de conocimiento
â”‚   â””â”€â”€ faqs_es.md
â”‚
â””â”€â”€ src/                           # CÃ³digo fuente
    â”œâ”€â”€ MAIN.py                    # Punto de entrada
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ __init__.py
    â”‚
    â”œâ”€â”€ beans/                     # DTOs y schemas
    â”‚   â”œâ”€â”€ api/
    â”‚   â”œâ”€â”€ schemas/
    â”‚   â””â”€â”€ services/
    â”‚
    â”œâ”€â”€ config/                    # ConfiguraciÃ³n
    â”‚   â””â”€â”€ settings.py
    â”‚
    â”œâ”€â”€ core/                      # Utilidades core
    â”‚   â”œâ”€â”€ i18n.py
    â”‚   â””â”€â”€ sentiment.py
    â”‚
    â”œâ”€â”€ llm/                       # IntegraciÃ³n LangChain
    â”‚   â”œâ”€â”€ chains.py
    â”‚   â”œâ”€â”€ memory.py
    â”‚   â”œâ”€â”€ models.py
    â”‚   â””â”€â”€ prompts.py
    â”‚
    â”œâ”€â”€ rag/                       # Sistema RAG
    â”‚   â”œâ”€â”€ ingest.py
    â”‚   â”œâ”€â”€ retriever.py
    â”‚   â””â”€â”€ store.py
    â”‚
    â”œâ”€â”€ routes/                    # Endpoints FastAPI
    â”‚   â”œâ”€â”€ admin/
    â”‚   â”œâ”€â”€ chat/
    â”‚   â””â”€â”€ health/
    â”‚
    â”œâ”€â”€ server/                    # Servidor FastAPI
    â”‚   â””â”€â”€ server.py
    â”‚
    â”œâ”€â”€ services/                  # LÃ³gica de negocio
    â”‚   â”œâ”€â”€ conversation.py
    â”‚   â”œâ”€â”€ extraction.py
    â”‚   â”œâ”€â”€ storage.py
    â”‚   â”œâ”€â”€ stt_tts.py
    â”‚   â””â”€â”€ summarization.py
    â”‚
    â”œâ”€â”€ utils/                     # Utilidades
    â”‚   â”œâ”€â”€ jsonio.py
    â”‚   â””â”€â”€ validators.py
    â”‚
    â””â”€â”€ tests/                     # Suite de tests (178 tests)
        â”œâ”€â”€ TEST_README.md         # DocumentaciÃ³n de tests
        â”œâ”€â”€ conftest.py            # Fixtures compartidos
        â”œâ”€â”€ test_api_endpoints.py  # Tests de API (13)
        â”œâ”€â”€ test_conversation.py   # Tests de conversaciÃ³n (17)
        â”œâ”€â”€ test_extraction.py     # Tests de extracciÃ³n (12)
        â”œâ”€â”€ test_jsonio.py         # Tests de JSON I/O (18)
        â”œâ”€â”€ test_llm_chains.py     # Tests de LLM chains (10)
        â”œâ”€â”€ test_llm_memory.py     # Tests de LLM memory (16)
        â”œâ”€â”€ test_memory.py         # Tests de memoria (17)
        â”œâ”€â”€ test_rag_system.py     # Tests de RAG (19)
        â”œâ”€â”€ test_sentiment.py      # Tests de sentimiento (8)
        â”œâ”€â”€ test_storage.py        # Tests de storage (15)
        â”œâ”€â”€ test_summarization.py  # Tests de resÃºmenes (10)
        â””â”€â”€ test_validators.py     # Tests de validadores (10)
```

---

## ğŸ”’ Seguridad

### Best Practices Implementadas

- âœ… **API Keys en .env**: Nunca hardcodeadas en cÃ³digo
- âœ… **ValidaciÃ³n robusta**: Pydantic valida todos los inputs
- âœ… **AutenticaciÃ³n admin**: Endpoints protegidos con API key
- âœ… **SanitizaciÃ³n**: Regex y lÃ­mites de longitud
- âœ… **No logging de secretos**: API keys nunca en logs
<!-- - âœ… **Docker no-root**: Usuario sin privilegios -->

### Recomendaciones para ProducciÃ³n

1. **Usar HTTPS**: Proxy reverso con Nginx + Let's Encrypt
2. **Rate limiting**: Implementar lÃ­mites por IP/usuario
3. **WAF**: Cloudflare o AWS WAF
4. **Secrets manager**: AWS Secrets Manager / HashiCorp Vault
5. **AuditorÃ­a**: Logs de acceso a endpoints admin
6. **Actualizaciones**: Mantener dependencias actualizadas

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia MIT.

---

## ğŸ‘¥ Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Fork el repositorio
2. Crea una rama para tu feature (`git checkout -b feature/amazing-feature`)
3. Commit tus cambios (`git commit -m 'Add amazing feature'`)
4. Push a la rama (`git push origin feature/amazing-feature`)
5. Abre un Pull Request

---

## ğŸ“ Soporte

Para preguntas, issues o sugerencias:

- **Issues**: Abre un issue en GitHub

---

## ğŸ™ Agradecimientos

Construido con:
- [LangChain](https://python.langchain.com/) - Framework LLM
- [FastAPI](https://fastapi.tiangolo.com/) - Framework web
- [FAISS](https://github.com/facebookresearch/faiss) - Vector store
- [Pydantic](https://docs.pydantic.dev/) - ValidaciÃ³n de datos
- [TextBlob](https://textblob.readthedocs.io/) - AnÃ¡lisis de sentimiento

---

**Desarrollado con â¤ï¸ byPGG para crear experiencias conversacionales inteligentes**
